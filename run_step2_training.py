#!/usr/bin/env python3
"""
SRAG-V Step 2: Core Training Loop Implementation
Complete integration of GRPO, MAP-Elites, and 4-player self-play training.

This script implements the breakthrough-level self-play training system
with emergent verification learning capabilities.
"""

import logging
import sys
import os
import time
from pathlib import Path
import json
import traceback

# Add src to path
sys.path.insert(0, str(Path(__file__).parent / "src"))

from sragv.orchestrator import SRAGVOrchestrator
from sragv.training.self_play_trainer import SelfPlayTrainer, SelfPlayConfig
from sragv.training.grpo_trainer import GRPOConfig
from sragv.training.map_elites import MAPElitesConfig

# Setup comprehensive logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('logs/step2_training.log')
    ]
)
logger = logging.getLogger(__name__)

# Create logs directory
Path("logs").mkdir(exist_ok=True)


def validate_prerequisites():
    """Validate that all Step 1 components are ready."""
    logger.info("üîç Validating Step 2 prerequisites...")
    
    checks = []
    
    # Check configuration
    config_path = Path("config/config.yaml")
    checks.append(("Configuration file", config_path.exists()))
    
    # Check expanded dataset
    dataset_path = Path("data/expanded_apps.json")
    checks.append(("Expanded dataset", dataset_path.exists()))
    
    if dataset_path.exists():
        with open(dataset_path, 'r') as f:
            data = json.load(f)
        checks.append(("Dataset size (‚â•2000)", len(data) >= 2000))
    
    # Check model cache
    cache_dir = Path.home() / ".cache/huggingface/hub"
    qwen_models = list(cache_dir.glob("models--Qwen--Qwen2.5*"))
    checks.append(("Qwen models cached", len(qwen_models) >= 3))
    
    # Check src directory structure
    src_checks = [
        "src/sragv/__init__.py",
        "src/sragv/orchestrator.py",
        "src/sragv/models/__init__.py",
        "src/sragv/training/grpo_trainer.py",
        "src/sragv/training/map_elites.py",
        "src/sragv/training/reward_system.py",
        "src/sragv/training/self_play_trainer.py"
    ]
    
    for check_path in src_checks:
        checks.append((f"Source: {check_path}", Path(check_path).exists()))
    
    # Report results
    logger.info("Prerequisites validation:")
    passed = 0
    for check_name, passed_check in checks:
        status = "‚úÖ PASS" if passed_check else "‚ùå FAIL"
        logger.info(f"  {check_name:<40} {status}")
        if passed_check:
            passed += 1
    
    success_rate = passed / len(checks)
    logger.info(f"Prerequisites: {passed}/{len(checks)} checks passed ({success_rate*100:.1f}%)")
    
    if success_rate < 0.8:
        logger.error("‚ùå Insufficient prerequisites for Step 2 training")
        return False
    
    logger.info("‚úÖ Prerequisites validation successful")
    return True


def create_optimized_training_config() -> SelfPlayConfig:
    """Create optimized training configuration based on research."""
    logger.info("üìã Creating optimized training configuration...")
    
    config = SelfPlayConfig(
        # Training schedule (12 iterations as per research)
        num_iterations=12,
        bootstrap_iterations=3,
        competitive_iterations=6,
        league_iterations=3,
        
        # Problem generation (research-validated optimization)
        problems_per_iteration=32,  # Maintains statistical significance (July 2025 research)
        dynamic_problem_generation=True,
        problem_difficulty_scaling=True,
        
        # Self-play dynamics (conservative optimization)
        solutions_per_problem=14,  # 12% reduction - maintains MAP-Elites diversity
        test_cases_per_problem=8,   # Full verification coverage (safety requirement)
        archive_sampling_probability=0.3,
        
        # Training optimization (memory and speed)
        gradient_accumulation_steps=4,
        mixed_precision=True,
        checkpoint_every_iterations=2,
        
        # Emergent behavior tracking (breakthrough detection)
        track_emergent_behaviors=True,
        behavior_analysis_frequency=2,  # Frequent analysis
        novel_pattern_threshold=0.8,
        
        # Quality gates (ensure robust training)
        min_solution_accuracy=0.6,  # Reasonable threshold
        min_test_validity=0.5,      # Allow learning from mistakes
        convergence_threshold=0.05  # Detect convergence
    )
    
    logger.info(f"Training configuration:")
    logger.info(f"  - {config.num_iterations} total iterations")
    logger.info(f"  - {config.problems_per_iteration} problems per iteration")
    logger.info(f"  - {config.solutions_per_problem} solutions per problem")
    logger.info(f"  - Emergent behavior tracking: {config.track_emergent_behaviors}")
    
    return config


def initialize_training_system(config: SelfPlayConfig) -> tuple:
    """Initialize the complete training system."""
    logger.info("üöÄ Initializing SRAG-V training system...")
    
    # Initialize orchestrator
    logger.info("  Initializing SRAG-V orchestrator...")
    orchestrator = SRAGVOrchestrator("config/config.yaml")
    
    # Initialize self-play trainer
    logger.info("  Initializing self-play trainer...")
    trainer = SelfPlayTrainer(
        orchestrator=orchestrator,
        config=config,
        checkpoint_dir="checkpoints/step2_training"
    )
    
    logger.info("‚úÖ Training system initialized successfully")
    return orchestrator, trainer


def run_training_with_monitoring(trainer: SelfPlayTrainer) -> dict:
    """Run training with comprehensive monitoring and error handling."""
    logger.info("üéØ Starting monitored training execution...")
    
    start_time = time.time()
    
    try:
        # Run the complete training
        results = trainer.run_self_play_training()
        
        training_time = time.time() - start_time
        results["total_training_time"] = training_time
        
        # Log final results
        logger.info("üéâ Training completed successfully!")
        logger.info(f"Total training time: {training_time:.1f}s ({training_time/60:.1f}min)")
        
        # Extract key metrics
        if "breakthrough_indicators" in results:
            breakthrough = results["breakthrough_indicators"]
            breakthrough_score = breakthrough.get("breakthrough_score", 0.0)
            logger.info(f"Breakthrough score: {breakthrough_score:.3f}/1.0")
            
            if breakthrough_score > 0.75:
                logger.info("üèÜ BREAKTHROUGH ACHIEVED! Novel verification behaviors detected!")
            elif breakthrough_score > 0.5:
                logger.info("üåü Significant emergent behaviors observed")
            else:
                logger.info("üìà Training successful, baseline behaviors established")
        
        if "final_archive_stats" in results:
            archive_stats = results["final_archive_stats"]
            logger.info(f"Final archive: {archive_stats.get('total_elites', 0)} elites, "
                       f"{archive_stats.get('occupied_niches', 0)} niches")
        
        return results
        
    except KeyboardInterrupt:
        logger.info("‚èπÔ∏è Training interrupted by user")
        # Save partial results
        results = {
            "status": "interrupted",
            "training_time": time.time() - start_time,
            "error": "User interrupted"
        }
        return results
        
    except Exception as e:
        logger.error(f"üí• Training failed: {e}")
        logger.error("Full traceback:")
        for line in traceback.format_exc().splitlines():
            logger.error(f"  {line}")
        
        # Save error results
        results = {
            "status": "failed",
            "training_time": time.time() - start_time,
            "error": str(e),
            "traceback": traceback.format_exc()
        }
        return results


def analyze_and_report_results(results: dict):
    """Analyze and report comprehensive training results."""
    logger.info("üìä Analyzing training results...")
    
    status = results.get("status", "completed")
    training_time = results.get("total_training_time", 0)
    
    logger.info("=" * 80)
    logger.info("SRAG-V STEP 2 TRAINING RESULTS")
    logger.info("=" * 80)
    
    # Basic metrics
    logger.info(f"Status: {status.upper()}")
    logger.info(f"Training time: {training_time:.1f}s ({training_time/60:.1f}min)")
    
    if status == "completed":
        # Iteration results
        iterations = results.get("iterations", [])
        if iterations:
            logger.info(f"Iterations completed: {len(iterations)}")
            avg_quality = sum(it.get("quality_score", 0) for it in iterations) / len(iterations)
            logger.info(f"Average quality score: {avg_quality:.3f}")
        
        # Convergence analysis
        convergence = results.get("convergence_analysis", {})
        if convergence.get("converged", False):
            logger.info(f"‚úÖ Training converged in {convergence.get('iterations_to_convergence', 'N/A')} iterations")
        else:
            logger.info("‚è≥ Training completed without full convergence")
        
        # Emergent behaviors
        behaviors = results.get("emergent_behaviors", {})
        novel_patterns = behaviors.get("novel_patterns_discovered", 0)
        logger.info(f"Novel patterns discovered: {novel_patterns}")
        
        breakthrough = results.get("breakthrough_indicators", {})
        breakthrough_score = breakthrough.get("breakthrough_score", 0.0)
        logger.info(f"Breakthrough score: {breakthrough_score:.3f}/1.0")
        
        # Archive statistics
        archive = results.get("final_archive_stats", {})
        logger.info(f"Archive: {archive.get('total_elites', 0)} elites in {archive.get('occupied_niches', 0)} niches")
        
        # Quality assessment
        if breakthrough_score > 0.75:
            logger.info("üèÜ EINSTEIN-LEVEL BREAKTHROUGH ACHIEVED!")
            logger.info("   Novel verification behaviors detected")
            logger.info("   Ready for paper submission and industry adoption")
        elif breakthrough_score > 0.5:
            logger.info("üåü SIGNIFICANT PROGRESS ACHIEVED!")
            logger.info("   Strong emergent behaviors observed")
            logger.info("   Promising foundation for further development")
        elif avg_quality > 0.7:
            logger.info("üìà SOLID BASELINE ESTABLISHED!")
            logger.info("   Training successful, system functional")
            logger.info("   Ready for Step 3 scaling")
        else:
            logger.info("‚ö†Ô∏è TRAINING COMPLETED WITH ISSUES")
            logger.info("   Consider parameter tuning or additional iterations")
    
    elif status == "interrupted":
        logger.info("‚èπÔ∏è Training was interrupted")
        logger.info("   Partial results may be available in checkpoints")
        
    elif status == "failed":
        error = results.get("error", "Unknown error")
        logger.info(f"üí• Training failed: {error}")
        logger.info("   Check logs for detailed error information")
    
    logger.info("=" * 80)
    
    # Save detailed report
    report_path = Path("logs/step2_final_report.json")
    with open(report_path, 'w') as f:
        json.dump(results, f, indent=2, default=str)
    
    logger.info(f"üìã Detailed report saved to: {report_path}")


def main():
    """Main execution function for Step 2 training."""
    logger.info("üöÄ SRAG-V STEP 2: CORE TRAINING LOOP IMPLEMENTATION")
    logger.info("=" * 80)
    logger.info("Implementing breakthrough-level self-play training with:")
    logger.info("  ‚úì GRPO (Group Relative Policy Optimization)")
    logger.info("  ‚úì MAP-Elites diversity mechanism")
    logger.info("  ‚úì Role-conditioned reward system")
    logger.info("  ‚úì Emergent behavior tracking")
    logger.info("  ‚úì 12-iteration self-play protocol")
    logger.info("=" * 80)
    
    try:
        # Step 1: Validate prerequisites
        if not validate_prerequisites():
            logger.error("‚ùå Prerequisites validation failed")
            return 1
        
        # Step 2: Create training configuration
        config = create_optimized_training_config()
        
        # Step 3: Initialize training system
        orchestrator, trainer = initialize_training_system(config)
        
        # Step 4: Run training with monitoring
        logger.info("üéØ Launching self-play training...")
        results = run_training_with_monitoring(trainer)
        
        # Step 5: Analyze and report results
        analyze_and_report_results(results)
        
        # Return success/failure code
        status = results.get("status", "completed")
        if status == "completed":
            breakthrough_score = results.get("breakthrough_indicators", {}).get("breakthrough_score", 0.0)
            if breakthrough_score > 0.5:
                logger.info("üéâ STEP 2 SUCCESSFULLY COMPLETED WITH BREAKTHROUGH POTENTIAL!")
                return 0
            else:
                logger.info("‚úÖ STEP 2 COMPLETED - READY FOR STEP 3")
                return 0
        elif status == "interrupted":
            logger.info("‚èπÔ∏è STEP 2 INTERRUPTED - PARTIAL COMPLETION")
            return 2
        else:
            logger.error("‚ùå STEP 2 FAILED")
            return 1
            
    except Exception as e:
        logger.error(f"üí• Critical error in Step 2 execution: {e}")
        logger.error("Full traceback:")
        for line in traceback.format_exc().splitlines():
            logger.error(f"  {line}")
        return 1


if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)